# ingest request storage quota, default 10 GB
default_max_storage_space_in_megabytes=10240
# ingest request allowed inactivity period before starting to send warning emails to its owner, default 60 days
days_of_inactivity_allowed_since_last_session=60
# ingest request allowed period (since creation) before starting to send warning emails to its owner, default 180 days
total_number_of_days_allowed_until_expiry=180
# ingest request allowed period, since the last warning email, before sending the next one, default 30 days
number_of_days_of_inactivity_allowed_since_last_warning_email=30
# file size limit for which the typechecker should check a file again (when importing from the archive), default 8MB
type_recheck_size_limit_in_megabytes=8
# used by ArchiveFileHelper.correctPathElement to truncate unreasonably long names
max_directory_name_length=100
# name of the base directories where the corpus files are stored
corpus_directory_base_name=Corpusstructure
# name of the directories where unlinked files of a corpus are stored
orphans_directory_base_name=sessions
# path of the base directory where the workspace directories and files are stored
workspace_base_directory=/lat/corpora/lamus2/workspaces/
# name of the directory where the uploaded files will be copied to
workspace_upload_directory_name=upload
# name of the directory, within a branch (collection) of the tree, where metadata will be stored
metadata_directory_name=Metadata
# name of the directory, within a branch (collection) of the tree, where resources will be stored
resources_directory_name=Resources
# path of the base directory where the deleted files will be moved to
trashcan_base_directory=/lat/corpora/version_archive/
# custom typechecker configuration (config_file1=folder1,folder2;config_file2=folder3,folder4)
custom_typechecker_config_files_and_folders=


db_httproot=${db.httproot}
db_localroot=${db.localroot}


crawler_hostname=${crawler.hostname}
crawler_domainname=${crawler.domainname}
#crawler_prefixes=${crawler.prefixes}
crawler_amsurl=${crawler.amsurl}
crawler_mdsurl=${crawler.mdsurl}

crawler_dbdriverclassname=${crawler.dbdriverclassname}
crawler_dburl=${crawler.dburl}
crawler_dbmaxactive=${crawler.dbmaxactive}
crawler_dbmaxwait=${crawler.dbmaxwait}
crawler_dbtestonborrow=${crawler.dbtestonborrow}
crawler_dbusername=${crawler.dbusername}
crawler_dbpassword=${crawler.dbpassword}
crawler_connectiondrivername=${crawler.connectiondrivername}
crawler_hdlproxydomain=${crawler.hdlproxydomain}


handle_prefix=${handle.prefix}
handle_proxy=${handle.proxy}
handle_admin_key_file=${handle.admin_key_file}
handle_admin_user_handle=${handle.admin_user_handle}
handle_admin_user_handle_index=${handle.admin_user_handle_index}
handle_admin_handle_password=${handle.admin_handle_password}